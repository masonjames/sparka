{
  "data": {
    "id": "meta/llama-3-8b",
    "name": "Llama 3 8B Instruct",
    "created": 1755815280,
    "description": "Llama is a 8 billion parameter open source model by Meta fine-tuned for instruction following purposes. Served by Groq with their custom Language Processing Units (LPUs) hardware to provide fast and efficient inference.",
    "architecture": {
      "tokenizer": null,
      "instruct_type": null,
      "modality": "textâ†’text",
      "input_modalities": [
        "text"
      ],
      "output_modalities": [
        "text"
      ]
    },
    "endpoints": [
      {
        "name": "groq | meta/llama-3-8b",
        "model_name": "Llama 3 8B Instruct",
        "context_length": 8192,
        "pricing": {
          "prompt": "0.00000005",
          "completion": "0.00000008",
          "request": "0",
          "image": "0",
          "image_output": "0",
          "web_search": "0",
          "internal_reasoning": "0",
          "discount": 0
        },
        "provider_name": "groq",
        "tag": "groq",
        "quantization": null,
        "max_completion_tokens": 8192,
        "max_prompt_tokens": null,
        "supported_parameters": [
          "max_tokens",
          "temperature",
          "stop"
        ],
        "status": 0,
        "uptime_last_30m": null,
        "supports_implicit_caching": false
      }
    ]
  }
}