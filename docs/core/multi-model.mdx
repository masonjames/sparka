---
title: "Multi-Model Support"
description: "Access hundreds of AI models through a pluggable gateway abstraction"
---

ChatJS provides access to hundreds of models from multiple providers through a pluggable [gateway system](/gateways/overview). Set `gateway` in `chat.config.ts` to choose your backend:

| Gateway | Models | Setup |
|---------|--------|-------|
| [Vercel AI Gateway](/gateways/vercel) (default) | 120+ | `AI_GATEWAY_API_KEY` |
| [OpenRouter](/gateways/openrouter) | Hundreds | `OPENROUTER_API_KEY` |
| [OpenAI](/gateways/openai) | OpenAI only | `OPENAI_API_KEY` |
| [OpenAI Compatible](/gateways/openai-compatible) | Varies | `OPENAI_COMPATIBLE_BASE_URL` |

## Model Registry Architecture

### Auto-Update (Runtime)

The app fetches available models from the active gateway's API at runtime. Results are cached for 1 hour.

```typescript
// lib/ai/models.ts
export const fetchModels = unstable_cache(
  async (): Promise<ModelData[]> => {
    const models = await fetchModelsRaw();
    return models.map(toModelData);
  },
  ["ai-gateway-models"],
  { revalidate: 3600, tags: ["ai-gateway-models"] }
);
```

When no API key is available, the app falls back to a static snapshot in `models.generated.ts`.

### Manual Update (Build-time)

To refresh the fallback snapshot, run:

```bash
bun fetch:models
```

This fetches current models from the gateway and writes them to `lib/ai/models.generated.ts`. Run this periodically to keep the fallback fresh.

## Model Configuration

All model settings are configured in `chat.config.ts` under the `models` key:

```typescript title="chat.config.ts"
models: {
  providerOrder: ["openai", "google", "anthropic", "xai"],
  disabledModels: ["morph/morph-v3-large", "morph/morph-v3-fast"],
  curatedDefaults: [
    "openai/gpt-5-nano",
    "openai/gpt-5-mini",
    "google/gemini-2.5-flash-lite",
    "anthropic/claude-sonnet-4.5",
    // ...
  ],
  anonymousModels: [
    "google/gemini-2.5-flash-lite",
    "openai/gpt-5-mini",
    // ...
  ],
  defaults: {
    chat: "openai/gpt-5-nano",
    title: "google/gemini-2.5-flash-lite",
    pdf: "openai/gpt-5-mini",
    artifact: "openai/gpt-5-nano",
    // ...
  },
},
```

| Setting           | Description                             |
| ----------------- | --------------------------------------- |
| `providerOrder`   | Provider sort order in model selector   |
| `disabledModels`  | Models hidden from all users            |
| `curatedDefaults` | Models enabled by default for new users |
| `anonymousModels` | Models available to anonymous users     |
| `defaults.*`      | Default model for each task type        |

<Note>
Image generation uses a separate `defaults.image` setting. Language models with the `image-generation` tag can also generate images inline. See [Image Generation](/features/image-generation) for details.
</Note>

## Reasoning Variants

Models that support extended thinking are automatically split into two variants:

- `{model-id}` (standard mode)
- `{model-id}-reasoning` (extended thinking enabled)

This happens automatically in `buildAppModels()` for any model with `reasoning: true`.

## Visibility Pipeline

Model visibility is determined through a pipeline:

### Authenticated Users

1. **Remove** disabled models (`models.disabledModels`)
2. **Apply defaults** (`models.curatedDefaults` + any new API models not in `models.generated.ts`)
3. **Apply user overrides** from saved preferences

### Anonymous Users

1. **Remove** disabled models
2. **Filter** to `models.anonymousModels` only

## User Settings

Users configure their model preferences at `/settings/models`. This page lets users toggle individual models on or off. A link to [AI Registry](https://airegistry.app) provides detailed model information.

## Environment Variables

The active gateway handles authentication with all providers. You authenticate with the gateway, not with individual providers:

| Gateway | Required Variable |
|---------|-------------------|
| [Vercel](/gateways/vercel) (default) | `AI_GATEWAY_API_KEY` or `VERCEL_OIDC_TOKEN` (auto on Vercel) |
| [OpenRouter](/gateways/openrouter) | `OPENROUTER_API_KEY` |
| [OpenAI](/gateways/openai) | `OPENAI_API_KEY` |
| [OpenAI Compatible](/gateways/openai-compatible) | `OPENAI_COMPATIBLE_BASE_URL` + optional `OPENAI_COMPATIBLE_API_KEY` |

Without the required key for your active gateway, the app uses the fallback model list and cannot make API calls to providers.

See [Gateways](/gateways/overview) for detailed setup instructions for each gateway.
